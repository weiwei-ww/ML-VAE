n_epochs: 50

epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
    limit: !ref <n_epochs>

lr: 0.0003
lr_wav2vec: 0.0001

wav2vec2: !new:speechbrain.lobes.models.huggingface_wav2vec.HuggingFaceWav2Vec2
    source: "facebook/wav2vec2-large-lv60"
    output_norm: True
    freeze: False
    save_path: !ref <output_dir>/wav2vec2_checkpoint

classifier: !new:blocks.fc_block.FCBlock
    fc_sizes:
        - 1024
        - 512
        - 128
        - 1

optimizers:
    adam_opt:
        opt_class: !name:torch.optim.Adam
            lr: !ref <lr>
        modules:
            - classifier
    wav2vec_opt:
        opt_class: !name:torch.optim.Adam
            lr: !ref <lr_wav2vec>
        modules:
            - wav2vec2

lr_annealing_adam: !new:speechbrain.nnet.schedulers.NewBobScheduler
    initial_value: !ref <lr>
    improvement_threshold: 0.0025
    annealing_factor: 0.8
    patient: 0

lr_annealing_wav2vec: !new:speechbrain.nnet.schedulers.NewBobScheduler
    initial_value: !ref <lr_wav2vec>
    improvement_threshold: 0.0025
    annealing_factor: 0.9

modules:
    wav2vec2: !ref <wav2vec2>
    classifier: !ref <classifier>

checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
  checkpoints_dir: !ref <output_dir>/checkpoints
  recoverables:
        classifier: !ref <classifier>
        wav2vec2: !ref <wav2vec2>
        lr_annealing_adam: !ref <lr_annealing_adam>
        lr_annealing_wav2vec: !ref <lr_annealing_wav2vec>
        counter: !ref <epoch_counter>


compute_cost: !name:speechbrain.nnet.losses.ctc_loss
ctc_stats: !name:speechbrain.utils.metric_stats.MetricStats
per_stats: !name:speechbrain.utils.metric_stats.ErrorRateStats
md_stats: !name:utils.md_metric_stats.MDMetricStats

metric_keys:
    - flvl_md.ACC
    - flvl_md.PRE
    - flvl_md.REC
    - flvl_md.F1

max_key: flvl_md.F1
