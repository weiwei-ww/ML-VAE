n_epochs: 50

epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
    limit: !ref <n_epochs>

# checkpointer
checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
    checkpoints_dir: !ref <output_dir>/checkpoints
    recoverables:
        encoder: !ref <encoder>
        decoder: !ref <decoder>
        epoch_counter: !ref <epoch_counter>

normalizer: !new:speechbrain.processing.features.InputNormalization
    norm_type: global

# model parameters
rnn_hidden_size: 512
rnn_num_layers: 2
rnn_dropout: 0.15

pi_fc_size: 128

latent_size: 32
num_components: 3

enc_fc_size: 64

dec_rnn_hidden_size: 512
dec_rnn_num_layers: 2
dec_rnn_dropout: 0.15
dec_fc_size: 64

rnn: !new:torch.nn.LSTM
    input_size: !ref <input_size>
    hidden_size: !ref <rnn_hidden_size>
    num_layers: !ref <rnn_num_layers>
    batch_first: True
    dropout: !ref <rnn_dropout>

pi_fc: !new:modules.fc_block.FCBlock
    fc_sizes:
        - !ref <rnn_hidden_size>
        - !ref <pi_fc_size>
        - !ref <pi_fc_size> // 2
        - 2

encoder: !new:modules.h_vae.HierarchicalVAE
    fc_sizes:
        - !ref <rnn_hidden_size>
        - !ref <enc_fc_size>
        - !ref <enc_fc_size>
    latent_size: !ref <latent_size>
    num_components: !ref <num_components>

decoder: !new:modules.decoder.Decoder
    input_size: !ref <latent_size>
    rnn_hidden_size: !ref <dec_rnn_hidden_size>
    rnn_num_layers: !ref <dec_rnn_num_layers>
    rnn_dropout: !ref <dec_rnn_dropout>
    fc_sizes:
        - !ref <dec_rnn_hidden_size> * 2
        - !ref <dec_fc_size>
        - !ref <dec_fc_size>
        - !ref <input_size>

lr: 0.001
optimizer: !name:torch.optim.Adam
    lr: !ref <lr>

modules:
    rnn: !ref <rnn>
    pi_fc: !ref <pi_fc>
    encoder: !ref <encoder>
    decoder: !ref <decoder>

# loss weights
vae_kld_weight: 0.001

# evaluation metrics
metric_keys:
    - vae_kld_loss
    - recon_loss

min_key: loss
